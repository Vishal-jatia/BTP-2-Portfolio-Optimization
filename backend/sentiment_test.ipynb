{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c92b0954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "def get_sentiment_score(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1).detach().numpy()[0]\n",
    "    return probs[2] - probs[0]  # Positive - Negative = Polarity score (c in [-1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f42304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "def simulate_price_paths(symbol, S0, mu, sigma, T=1, steps=45, n_paths=10000):\n",
    "    \"\"\"\n",
    "    Simulate multiple price paths for a given financial asset using the Geometric Brownian Motion model.\n",
    "\n",
    "    Parameters:\n",
    "        symbol (str): The ticker symbol of the asset.\n",
    "        S0 (float): The initial price of the asset.\n",
    "        mu (float): The expected return (drift) of the asset.\n",
    "        sigma (float): The volatility of the asset.\n",
    "        T (float, optional): The total time period for the simulation. Default is 1.\n",
    "        steps (int, optional): The number of time steps in the simulation. Default is 45.\n",
    "        n_paths (int, optional): The number of simulated paths. Default is 10000.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 2D array where each column represents a simulated price path over time.\n",
    "    \"\"\"\n",
    "    dt = T / steps\n",
    "    paths = np.zeros((steps, n_paths))\n",
    "    paths[0] = S0\n",
    "    for t in range(1, steps):\n",
    "        Z = np.random.standard_normal(n_paths)\n",
    "        paths[t] = paths[t-1] * np.exp((mu - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * Z)\n",
    "    return paths\n",
    "\n",
    "def get_ST_from_sentiment(paths, c, S0):\n",
    "    if c >= 0:\n",
    "        return S0 + (paths[-1].max() - S0) * c\n",
    "    else:\n",
    "        return S0 - (S0 - paths[-1].min()) * abs(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53857cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[150.         150.         150.         ... 150.         150.\n",
      "  150.        ]\n",
      " [158.97232217 146.00195417 152.06671276 ... 154.96344805 143.66116566\n",
      "  145.33651203]\n",
      " [157.68881561 146.0947992  157.98361789 ... 162.3371403  147.92634404\n",
      "  144.56278117]\n",
      " ...\n",
      " [149.48048844 235.73604098 180.31713422 ... 127.85185074 145.22726352\n",
      "  148.11969146]\n",
      " [147.15086314 227.32540181 174.40246761 ... 129.19321513 153.03342225\n",
      "  148.45172816]\n",
      " [141.47043401 218.64473497 179.15358751 ... 138.24751324 151.62402925\n",
      "  150.63916576]]\n",
      "151.62274766154147\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "symbol = \"AAPL\"\n",
    "S0 = 150  # Initial stock price\n",
    "mu = 0.05  # Expected return\n",
    "sigma = 0.2  # Volatility\n",
    "T = 1  # Time period in years\n",
    "steps = 45  # Number of time steps\n",
    "n_paths = 10000  # Number of simulated paths\n",
    "\n",
    "paths = simulate_price_paths(symbol, S0, mu, sigma, T, steps, n_paths)\n",
    "future_prices = get_ST_from_sentiment(paths=paths, c=0.008440747, S0=S0)\n",
    "print(paths)\n",
    "print(future_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea810ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_yield(ST, S0):\n",
    "    return np.log(ST / S0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2149758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.black_litterman import BlackLittermanModel, market_implied_prior_returns\n",
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "\n",
    "def apply_black_litterman(prices_df, sentiment_views, tau=0.05):\n",
    "    S = CovarianceShrinkage(prices_df).ledoit_wolf()\n",
    "    mu = mean_historical_return(prices_df)\n",
    "    market_weights = np.array([1/len(prices_df.columns)] * len(prices_df.columns))\n",
    "    delta = market_weights.T @ mu.values\n",
    "    pi = market_implied_prior_returns(market_weights, S, delta)\n",
    "    \n",
    "    P = np.eye(len(sentiment_views))\n",
    "    Q = np.array([sentiment_views[s] for s in prices_df.columns])\n",
    "    \n",
    "    bl = BlackLittermanModel(S, pi=pi, Q=Q, P=P, omega=\"idzorek\", tau=tau)\n",
    "    ret_bl = bl.bl_returns()\n",
    "    cov_bl = bl.bl_cov()\n",
    "    \n",
    "    ef = EfficientFrontier(ret_bl, cov_bl)\n",
    "    weights = ef.max_sharpe()\n",
    "    return ef.clean_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a06a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import re\n",
    "\n",
    "def fetch_articles_from_google_news(ticker, max_articles=5):\n",
    "    rss_url = f\"https://news.google.com/rss/search?q={ticker}+stock\"\n",
    "    feed = feedparser.parse(rss_url)\n",
    "    articles = []\n",
    "\n",
    "    for entry in feed.entries[:max_articles]:\n",
    "        title = entry.title\n",
    "        link = entry.link\n",
    "        articles.append({\"title\": title, \"link\": link})\n",
    "\n",
    "    return articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ed84ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "def fetch_yfinance_news(ticker, max_entries=5):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    news = stock.news[:max_entries]\n",
    "    return [{\"title\": item['content']['title'], \"link\": item['content']['canonicalUrl']['url']} for item in news]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6dec4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Google News:\n",
      "â€¢ Is Apple Inc. (NASDAQ:AAPL) the Best Tech Stock to Buy For Long-Term Investment? - Yahoo Finance â†’ https://news.google.com/rss/articles/CBMifEFVX3lxTE5INlM5aHRlSWdyd3lxTW5qUW5zUXl4anY5T1V4TURtRXQzTVV0dGphSHZEdTVhcHB5Szk4R0pOcnJRZmpqcU1POEFGcndlTURjank5cXdLVy1XX1M5cmFKdGlwc0R4UmFGSllJMVlaRzAyV1RIWEw2N0o2Tm8?oc=5\n",
      "â€¢ Apple Was The Top Smartphone Seller In Q1. Does That Make AAPL Stock A Buy Here? - Barchart.com â†’ https://news.google.com/rss/articles/CBMiwAFBVV95cUxNeDFlVnFVVXVDVkdFMWJHMU16cEpvRGlQOEtzRlo4ZkdUZ2ZnenZWSWhwd0NXcGpuZi12S1dQVDJuX25FVmVSVmZqeE5WTmVON2lidE9YenJfU2dwS2Q1Qjd2SXE1ZjhSUmFyazVlWERhTmhQUGJlTm1UWW10cFoxRzFwZEY5a1pVNGllRUR4bWRBWndESG9kdl9mRl9JT3hibnJnRXZLeTZ3UGRkc2puUDdhZldZU2pZQ195bGlLNVg?oc=5\n",
      "â€¢ Magnificent Seven Stocks Watch: Nvidia, Tesla Sell Off - Investor's Business Daily â†’ https://news.google.com/rss/articles/CBMie0FVX3lxTFB6UE0zMU96cW1vdmN1cE1RQjd4RzlqbFVycEk2VlVNRFY3aDFmU1E2eGYyQi1XV09zTEF3SnFaZVMtMWJiV3VzVmtrSy1KNXZZYUctTXgxOFNJRkFRaFJiUkZHSjBaNHM1SU5iTmpFQ0NvYUlVeXIzaUF2aw?oc=5\n",
      "â€¢ Stocks making the biggest moves premarket: Apple, Nvidia, Goldman Sachs, Pfizer and more - CNBC â†’ https://news.google.com/rss/articles/CBMipwFBVV95cUxNRWVFeUoxa2tqcm00T2x4eW1uLVUweWNQRWtiUElnVVkzSmk0YUR4VnluOHY0VWt4WVE1SDJwWDlVeXZpZGczV1B0Rm0ydUUtMUlCVlhVNUlpMmVwR2tWREVBaWhycVRIUzc4SEprQ0hmUFdFXzVlbXJJWmFMdHdzYWstMFlUN0dBOE5WbUFRb241Rk93WTJoWUw5MTlVdWh1M3lQcG8taw?oc=5\n",
      "â€¢ What to Expect From Appleâ€™s Q2 2025 Earnings Report - Nasdaq â†’ https://news.google.com/rss/articles/CBMif0FVX3lxTE1IbXFSSDNxRXd3cFp5Z0VKYzJtNmZyOHFETzdwNm00Qm5DcFQ1ZGlSdkJNN09WRlFQOUxhVGV4LU9Ib1lSU3R5aHV2a05LNjZfZXR0MF9qRkUtWFdHSjNZMzhpcGpZaDAyTnBmRm9FbVZlbFFIVlVhZXZjT0tVRGM?oc=5\n",
      "\n",
      "ðŸ“ˆ Yahoo Finance News:\n",
      "â€¢ The Best Warren Buffett Stocks to Buy With $1,000 Right Now â†’ https://www.fool.com/investing/2025/04/18/the-best-warren-buffett-stocks-to-buy-with-1000-ri/?source=eptyholnk0000202&utm_source=yahoo-host-full&utm_medium=feed&utm_campaign=article&referring_guid=0fc538b4-b833-4b06-9d67-ad1ef2430468\n",
      "â€¢ Apple Loses Ground in Chinaâ€™s Smartphone Market as Local Rivals Gain â†’ https://www.wsj.com/tech/apple-loses-ground-in-chinas-smartphone-market-as-local-rivals-gain-0431f373?siteid=yhoof2&yptr=yahoo\n",
      "â€¢ Apple Inc. (AAPL)â€™s Global Supply Shift Could Cushion AI Growth Against Tariff Risks â†’ https://finance.yahoo.com/news/apple-inc-aapl-global-supply-032351110.html\n",
      "â€¢ Steve Jobs Said 14 Years Ago iPhones Would Never Be Made In The U.S.: 'Those Jobs Aren't Coming Back'â€”Now Tariffs Could Bump Price To $3,500 â†’ https://finance.yahoo.com/news/steve-jobs-said-14-years-223049401.html\n",
      "â€¢ Top Analyst Reports for Apple, Philip Morris & Sony â†’ https://finance.yahoo.com/news/top-analyst-reports-apple-philip-205900016.html\n"
     ]
    }
   ],
   "source": [
    "ticker = \"AAPL\"\n",
    "\n",
    "print(\"ðŸ”Ž Google News:\")\n",
    "articles = fetch_articles_from_google_news(ticker)\n",
    "for a in articles:\n",
    "    print(f\"â€¢ {a['title']} â†’ {a['link']}\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Yahoo Finance News:\")\n",
    "reports = fetch_yfinance_news(ticker)\n",
    "for r in reports:\n",
    "    print(f\"â€¢ {r['title']} â†’ {r['link']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8b5ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "\n",
    "def extract_article_text(url):\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return article.text\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4234b36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'The Best Warren Buffett Stocks to Buy With $1,000 Right Now', 'link': 'https://www.fool.com/investing/2025/04/18/the-best-warren-buffett-stocks-to-buy-with-1000-ri/?source=eptyholnk0000202&utm_source=yahoo-host-full&utm_medium=feed&utm_campaign=article&referring_guid=0fc538b4-b833-4b06-9d67-ad1ef2430468', 'text': 'The Oracle of Omaha has already done the hard work for you. Just follow his lead.\\n\\nGot an extra $1,000 you\\'re ready to put to work for a while but don\\'t know what to buy? Don\\'t make it complicated. Borrow a pick or two -- or more -- from the market\\'s most proven stock picker. That\\'s Warren Buffett, of course, chief investment guru of Berkshire Hathaway (BRK.A 0.82%) (BRK.B 0.39%), which regularly outshines the S&P 500\\'s long-term performance. Credit Buffett\\'s stock-picking prowess, mostly.\\n\\nWith that as the backdrop, here\\'s a closer look at three Buffett/Berkshire holdings that would be good all-around picks for nearly investor.\\n\\nApple\\n\\nIt\\'s such a frequently suggested pick that it\\'s almost become clichÃ©. Nevertheless, Apple (AAPL 1.36%) is a prospect that would be at home in almost everyone\\'s portfolio.\\n\\nNot everyone will necessarily agree with this call. Revenue stagnated again following 2021\\'s modest progress, in step with stagnating iPhone sales (which accounts for about half of the company\\'s top line). Shares rallied last year on the belief that the company\\'s newer artificial intelligence (AI)-capable smartphones would reignite growth. But, as it turns out, what the company\\'s calling Apple Intelligence isn\\'t quite the draw it was hoped. Indeed, the latest version of its AI-powered virtual assistant Siri can arguably be considered a flop that\\'s since been sent back to the proverbial drawing board. The subsequent dent in the company\\'s reputation is the big reason Apple shares are now down more than 20% from their late-2024 peak.\\n\\nDon\\'t jump to long-term conclusions about this company\\'s long-term future based on its near-term results, however. This is still Apple. While it was undeniably late to the AI party and admittedly launched the newest version of Siri before it was ready, artificial intelligence still plays prominently in everyone\\'s future.\\n\\nMarket research outfit Next Move Strategy Consulting predicts the consumer-facing sliver of the AI market is set to grow at an annualized pace of 28% through 2030, while Market.us believes the worldwide personal AI assistant market will grow at an average annual pace of 38% between now and 2034. People just need a little more education, and a little more time.\\n\\nThis tailwind of course bodes well for Apple.\\n\\nThis might convince you: Although Berkshire\\'s been paring back its stake in Apple of late, at a value of $60 billion it\\'s still by far the conglomerate\\'s single biggest position, making up more than 20% of its stock holdings.\\n\\nVeriSign\\n\\nWhile Apple is a name everyone\\'s heard of, VeriSign (VRSN 0.27%) is anything but. It\\'s not even a particularly big deal to Buffett and his lieutenants. Although Berkshire owns 14% of the company, with only 13.3 million shares worth a grand total of $3.3 billion, VeriSign only makes up 1.2% of Berkshire\\'s holdings in publicly traded companies.\\n\\nStill, the fact that Buffett wants to own any size piece of VeriSign is telling, and bullish.\\n\\nIn simplest terms, VeriSign is the organization responsible for registering websites that end with a \".com\" and \".net\" suffix. It also handles \".cc\" and \".name\" sites, but dot-coms and dot-nets make up the bulk of world\\'s websites. The company also offers a handful of cyber defense and technological solutions, but domain registrations are its big business.\\n\\nThere are registration fees involved, of course, albeit modest ones. The World Wide Web is also already pretty well crowded, with not a great deal of need for new sites. That\\'s why single-digit revenue growth here is the norm.\\n\\nWhat VeriSign lacks in growth firepower, however, it more than makes up for in consistency. Revenue has grown every single quarter (year over year) for well over a decade now, in fact, while operating income has grown almost as a reliably, and certainly just as quickly. Plenty of companies envy this steady forward progress.\\n\\nIt makes sense, of course. After all, the internet is here to stay.\\n\\nVeriSign isn\\'t a cheap stock, mind you. Indeed, thanks to a pronounced run-up since late last year the stock\\'s trading at nearly 30 times this year\\'s expected per-share earnings of $8.68, and within sight of analysts\\' consensus price target of $267.50. You could have gotten this stock at a lower price just a few months back. And you might be able to buy it cheaper at some point in the foreseeable future.\\n\\nAs Buffett reminds investors though, \"It\\'s far better to buy a wonderful company at a fair price than a fair company at a wonderful price.\" In other words, holding out for a bargain price often ends up hurting more than helping.\\n\\nBerkshire Hathaway\\n\\nFinally, it\\'s a frequently glossed-over fact that Buffett doesn\\'t directly own many -- if any -- of what are often called \"Warren Buffett stocks.\" These stocks in question are almost always just equities held by the Berkshire Hathaway company. The bulk of Buffett\\'s personal wealth is instead actually tied up in the 15% (equivalent) of Berkshire that he directly holds, which of course means he only indirectly owns a piece of every so-called \"Buffett stock.\"\\n\\nThe thing is, you can do the very same for yourself. That is to say, you can own the very same sort of stake in Berkshire Hathaway that Buffett himself does. At a price of just over $500 apiece, in fact, a $1,000 investment would get you a couple of Berkshire\\'s Class B shares.\\n\\nDoing so would certainly solve a lot of problems for investors looking for an easy, efficient way of buying and holding a Buffett-approved portfolio, too. Not only will you own a proportional stake in everything that Buffett and his lieutenants like, any changes they might make to Berkshire\\'s holdings are automatically made on your behalf -- not unlike a mutual fund or exchange-traded fund (ETF).\\n\\nIt\\'s the other nuance, however, that makes this option a brilliant choice. That\\'s the fact that holding a position in Berkshire Hathway shares means you own a stake in several dozen privately held cash-cow companies that make up roughly one-third of the conglomerate\\'s total market cap. These include Clayton Homes, GEICO Insurance, Duracell, Dairy Queen, Pilot Travel Centers, and flooring company Shaw just to name a few. These cash-generating outfits play a crucial role in Buffett\\'s bigger-picture strategy, which can sometimes include just accumulating a war chest while waiting for the right opportunity to present itself.\\n\\nThis strategy has proven brilliant time and time again, including recently. Despite being underinvested with than $100 billion worth of idle cash on the books since 2019 and more than $300 billion just since late last year, Berkshire shares have easily beaten the market over the course of the past three years, reclaiming their long-term lead as a result.\\n\\nThere\\'s no reason to think the underpinning of this performance will be any different in the near or distant future either.'}, {'title': 'Apple Loses Ground in Chinaâ€™s Smartphone Market as Local Rivals Gain', 'link': 'https://www.wsj.com/tech/apple-loses-ground-in-chinas-smartphone-market-as-local-rivals-gain-0431f373?siteid=yhoof2&yptr=yahoo', 'text': None}, {'title': 'Apple Inc. (AAPL)â€™s Global Supply Shift Could Cushion AI Growth Against Tariff Risks', 'link': 'https://finance.yahoo.com/news/apple-inc-aapl-global-supply-032351110.html', 'text': 'We recently published a list of 10 AI Stocks Surging on News Today. In this article, we are going to take a look at where Apple Inc. (NASDAQ:AAPL) stands against other AI stocks surging on news today.\\n\\nIn the latest efforts to stop China from getting ahead in the AI race, the Trump administration is considering penalties that would block Chinaâ€™s DeepSeek from buying U.S. technology, reports The New York Times. It has also been reported that the administration is currently debating Americansâ€™ access to its services. DeepSeek, a Chinese start-up that shook up Wall Street a few months ago with its cheaper and more efficient AI models, has had the US taking firm steps to tighten controls and scrutinize tech investments.\\n\\nA key focus of US export controls has been Nvidia, whose chips were used to build DeepSeekâ€™s AI models. Even though the US had stringent export controls, the AI start-up managed to get hold of thousands of its GPUs, raising concerns about the effectiveness of the said controls. As a result, US officials now aim to prevent the most advanced chips from being sold to China to deter it from having a lead in the AI race.\\n\\nREAD NOW: 12 AI Stocks on Wall Streetâ€™s Radar and 10 AI Stocks You Shouldnâ€™t Overlook Right Now\\n\\nThe U.S. House Select Committee on China said that â€œit has sent a formal letter to Nvidia demanding answers about sales to China and Southeast Asia to examine whether and how its chips ended up powering DeepSeekâ€™s AI modelsâ€”despite U.S. export restrictionsâ€.\\n\\nWith the government tightening its export rules to China, the AI chipmaker has revealed how it would face a $5.5bn (Â£4.2bn) hit in costs. The company will now require licences to export its H20 AI chip to China, one of its most popular chips.\\n\\nâ€œThe [government] indicated that the license requirement addresses the risk that the covered products may be used in, or diverted to, a supercomputer in China.â€\\n\\nThe company also said that federal officials have advised them that the licence requirement â€œwill be in effect for the indefinite futureâ€.\\n\\nAccording to Marc Einstein from the Counterpoint Research consultancy, the $5.5bn hit is in line with estimates.\\n\\nâ€œAs we have seen in the last few days and weeks, this may largely be a negotiating tactic. I wouldnâ€™t be surprised to see some exemptions or changes made to tariff policy in the near future.â€\\n\\nFor this article, we selected AI stocks by going through news articles, stock analysis, and press releases. These stocks are also popular among hedge funds. The hedge fund data is as of Q4 2024.'}, {'title': \"Steve Jobs Said 14 Years Ago iPhones Would Never Be Made In The U.S.: 'Those Jobs Aren't Coming Back'â€”Now Tariffs Could Bump Price To $3,500\", 'link': 'https://finance.yahoo.com/news/steve-jobs-said-14-years-223049401.html', 'text': 'Apple\\'s (NASDAQ:AAPL) biggest iPhone headache might not be a chip shortage â€” it\\'s tariffs. President Donald Trump\\'s aggressive new round of China tariffs has temporarily spared electronics like smartphones and laptops, but that grace period is short-lived.\\n\\nCommerce Secretary Howard Lutnick on Sunday told ABC\\'s \"This Week\" that Apple and other tech companies should expect new semiconductor-specific tariffs \"in probably a month or two.\"\\n\\nApple\\'s dependence on China is massive. Roughly 90% of iPhones are made there. As The Guardian reports, if tariffs stick and Apple doesn\\'t shift production, the iPhone 16 Pro Max could jump from $1,199 to $2,150 â€” or even $3,500 if production were forced into the U.S.\\n\\nDon\\'t Miss:\\n\\nIronically, this was a debate 14 years ago.\\n\\nAt a 2011 Silicon Valley dinner with then-President Barack Obama, Apple CEO Steve Jobs gave a blunt answer when asked what it would take to make iPhones in America: \"Those jobs aren\\'t coming back.\" That quote, reported by The New York Times, captured the stark reality of globalized manufacturing.\\n\\nIt wasn\\'t just about labor costs. At the time of the 2011 article, experts estimated that paying American wages would only add about $65 to each iPhone.\\n\\nThe real issue was China\\'s supply chain dominance. \"You need a million screws? That factory is a block away,\" a former Apple executive told the Times.\\n\\nIn that same dinner, Jobs said that Apple could potentially bring some high-skill manufacturing to the U.S. if the government helped train engineers. But he was clear: America didn\\'t have the mid-level engineering workforce or production speed needed to compete.\\n\\nTrending: BlackRock is calling 2025 the year of alternative assets. One firm from NYC has quietly built a group of 60,000+ investors who have all joined in on an alt asset class previously exclusive to billionaires like Bezos and Gates.\\n\\nCurrent Apple CEO Tim Cook has tried to soften that stance. Apple in Februay announced plans to invest $500 billion in the U.S. over four years, building a new factory in Texas and expanding teams across 10 states. But most iPhones are still made abroad.\\n\\nEven back in 2012, Cook pledged $100 million to build some Mac computers in the U.S. While this move garnered attention, analysts viewed it as a strategic decision rather than a significant shift in Apple\\'s manufacturing strategy. Tom Dinges, a senior supply chain analyst at IHS, told Wired the impact would be minimal across Apple\\'s global operations.'}, {'title': 'Top Analyst Reports for Apple, Philip Morris & Sony', 'link': 'https://finance.yahoo.com/news/top-analyst-reports-apple-philip-205900016.html', 'text': \"Thursday, April 17, 2025\\n\\n\\n\\nThe Zacks Research Daily presents the best research output of our analyst team. Today's Research Daily features new research reports on 16 major stocks, including Bank of Apple Inc. (AAPL), Philip Morris International Inc. (PM) and Sony Group Corp. (SONY), as well as a micro-cap stock Vaso Corp. (VASO). The Zacks microcap research is unique as our research content on these small and under-the-radar companies is the only research of its type in the country.\\n\\n\\n\\nThese research reports have been hand-picked from the roughly 70 reports published by our analyst team today.\\n\\n\\n\\nYou can see all of todayâ€™s research reports here >>>\\n\\n\\n\\nAhead of Wall Street\\n\\n\\n\\nThe daily 'Ahead of Wall Street' article is a must-read for all investors who would like to be ready for that day's trading action. The article comes out before the market opens and attempts to make sense of that morning's economic releases and how they will affect that day's market action. You can read this article for free on our home page and can actually sign up there to get an email notification as this article comes out each morning.\\n\\n\\n\\nYou can read today's AWS here >>> Pre-Market Drama Shifts: Dow Lower on UNH Miss\\n\\n\\n\\nToday's Featured Research Reports\\n\\n\\n\\nAppleâ€™s shares have outperformed the Zacks Computer - Micro Computers industry over the past year (+16.8% vs. +15.2%). The company is benefiting from strong growth in Services revenues. It now has more than 1 billion paid subscribers across its Services portfolio, more than double what it had four years ago.\\n\\n\\n\\nThe expanding content portfolio of Apple TV+ and Apple Arcade helped in driving subscriber growth. Apple expects the March quarterâ€™s (second-quarter fiscal 2025) revenues to grow low to mid-single digits on a year-over-year basis. For the Services segment, it expects a low double-digit growth rate.\\n\\n\\n\\nIntroduction of Apple Intelligence, an advanced personal intelligence system seamlessly integrated into iOS 18, iPadOS 18 and macOS Sequoia will help Apple shares to push higher. However, weakness in iPhone sales particularly in China is a concern. Increasing regulatory headwinds is a headwind.\\n\\n\\n\\n(You can read the full research report on Apple here >>>)\\n\\n\\n\\nShares of Philip Morris have outperformed the Zacks Tobacco industry over the past year (+83.9% vs. +71.7%). The companyâ€™s strong pricing power and an expanding smoke-free product portfolio have been driving the company. For the fourth quarter of 2024, net revenues increased 7.3%, driven by higher combustible tobacco pricing and increased smoke-free product volumes.\\n\\n\\n\\nPhilip Morris has been making significant progress with its smoke-free transition, with products like IQOS and ZYN contributing to strong performance. In fact, Philip Morris aims to become substantially smoke-free by 2030.\\n\\n\\n\\nHowever, foreign currency fluctuations are impacting earnings, with a projected 22-cent-per-share currency headwind in 2025. Despite regulatory challenges, including increased tobacco restrictions, the companyâ€™s strategic cost-saving measures and operational efficiency continue to drive profitability.\\n\\n\\n\\n(You can read the full research report on Philip Morris here >>>)\\n\\n\\n\\nSonyâ€™s shares have outperformed the Zacks Audio Video Production industry over the past year (+42.6% vs. +36.9%). The company is poised to grow on strength across Game & Network Services (G&NS), Music and Financial Services amid woes in the Entertainment, Technology & Services (ET&S) unit. Financial Services revenues are benefiting from sales growth at Sony Life and higher investment gains from market volatility.\\n\\n\\n\\nThe Music unitâ€™s sales are backed by higher revenues from streaming services in Recorded Music and Music Publishing. Solid hardware and non-first-party game software sales and forex impacts are fueling the GN&S unit. Driven by momentum in Financial Services and G&NS units, it has raised its fiscal 2024 sales view to Â¥13,200 billion from Â¥12,710 billion.\\n\\n\\n\\nHowever, a fall in television and smartphone sales due to lower unit shipments hurt ET&S. Soft sales of image sensors for mobile products and lower unit sales are likely to weigh on the I&SS unit.\\n\\n\\n\\n(You can read the full research report on Sony here >>>)\\n\\n\\n\\nShares of Vaso have outperformed the Zacks Medical - Instruments industry over the year-to-date period (+10.4% vs. -12.6%). This microcap company with market capitalization of $23.26 million have diversified model across IT services, professional sales and medical devices which drove 2024 revenues by 7.1% to $86.8 million, with IT and GEHC sales growing 6.4% and 9.3%, respectively.\\n\\n\\n\\nStrong IT and sales momentum, a $34.9 million deferred revenue base and seasonal fourth-quarter 2024 strength enhance visibility. Despite 80.2% lower net income, Vaso remains debt-free with $26.3 million in cash and $3.3 million in operating cash flow, enabling funding flexibility despite SG&A growth and a failed merger.\\n\\n\\n\\nChallenges include cost inflation, overreliance on GEHC (47.6% of revenue), SaaS weakness and margin pressure. While investments aim to scale operations, profitability deterioration and M&A missteps pose execution risks amid rising competition in digital health. Vaso shares also suggest potential upside for value-focused investors.\\n\\n\\n\\n(You can read the full research report on Vaso here >>>)\\n\\n\\n\\nOther noteworthy reports we are featuring today include 3M Co. (MMM), The Travelers Companies, Inc. (TRV) and Expand Energy Corp. (EXE).\\n\\n\\n\\nMark Vickery\\n\\nSenior Editor\\n\\n\\n\\nNote: Sheraz Mian heads the Zacks Equity Research department and is a well-regarded expert of aggregate earnings. He is frequently quoted in the print and electronic media and publishes the weekly Earnings Trends and Earnings Preview reports. If you want an email notification each time Sheraz publishes a new article, please click here>>>\"}]\n"
     ]
    }
   ],
   "source": [
    "def extract_text(reports):\n",
    "    for r in reports:\n",
    "        link = r.get('link')\n",
    "        if link:\n",
    "            try:\n",
    "                r[\"text\"] = extract_article_text(link)\n",
    "            except Exception as e:\n",
    "                r[\"text\"] = None\n",
    "                print(f\"Failed to extract text from {link}: {e}\")\n",
    "    return reports\n",
    "\n",
    "\n",
    "print(extract_text(reports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e7a1aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.053710118\n",
      "0.11429344\n",
      "0.6469492\n",
      "-0.703268\n"
     ]
    }
   ],
   "source": [
    "for r in reports:\n",
    "    text = r.get(\"text\")\n",
    "    if text is not None:\n",
    "        print(get_sentiment_score(text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d12c88ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b52a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.algorithms.moo.moead import MOEAD\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.util.ref_dirs import get_reference_directions\n",
    "\n",
    "def predict_with_sentiment_ann(models, data, sentiment_scores, duration=\"1y\"):\n",
    "    logger.info(\"Running ANN + Sentiment-enhanced predictions\")\n",
    "    future_prices = {}\n",
    "    duration_map = {\"6m\": 180, \"1y\": 365, \"5y\": 1825, \"10y\": 3650}\n",
    "    prediction_days = duration_map.get(duration, 365)\n",
    "\n",
    "    for ticker, model in models.items():\n",
    "        last_10_days = np.array(data[ticker][-10:]).reshape(1, -1)\n",
    "        future_preds = []\n",
    "        sentiment_factor = sentiment_scores.get(ticker, 0)\n",
    "\n",
    "        for _ in range(prediction_days):\n",
    "            predicted_price = model.predict(last_10_days)[0][0]\n",
    "\n",
    "            # Modify prediction based on sentiment (polarity in [-1, 1])\n",
    "            adjusted_price = predicted_price * (1 + 0.1 * sentiment_factor)\n",
    "            future_preds.append(adjusted_price)\n",
    "\n",
    "            last_10_days = np.roll(last_10_days, -1)\n",
    "            last_10_days[0, -1] = adjusted_price\n",
    "\n",
    "        future_prices[ticker] = future_preds\n",
    "        logger.debug(f\"{ticker} - Avg predicted price: {np.mean(future_preds):.2f} with sentiment {sentiment_factor:.2f}\")\n",
    "\n",
    "    return future_prices\n",
    "\n",
    "def optimize_with_bl_and_moo(future_prices, prices_df, sentiment_scores, return_res):\n",
    "    logger.info(\"Running hybrid Blackâ€“Litterman + NSGA3 optimization\")\n",
    "\n",
    "    # Step 1: Compute returns and risks\n",
    "    tickers = list(future_prices.keys())\n",
    "    ann_returns = np.array([np.mean(future_prices[t]) for t in tickers])\n",
    "    ann_risks = np.array([np.std(future_prices[t]) for t in tickers])\n",
    "\n",
    "    # Normalize returns and risks\n",
    "    scaler = MinMaxScaler()\n",
    "    norm_returns = scaler.fit_transform(ann_returns.reshape(-1, 1)).flatten()\n",
    "    norm_risks = scaler.fit_transform(ann_risks.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Step 2: Black-Litterman with sentiment views\n",
    "    S = CovarianceShrinkage(prices_df).ledoit_wolf()\n",
    "    mu = mean_historical_return(prices_df)\n",
    "    market_weights = pd.Series(1 / len(tickers), index=tickers)\n",
    "    delta = 2.5\n",
    "    pi = market_implied_prior_returns(cov_matrix=S, market_caps=market_weights, risk_aversion=delta)\n",
    "\n",
    "    P = np.eye(len(tickers))\n",
    "    Q = np.array([sentiment_scores[t] for t in tickers])\n",
    "    view_confidences = np.clip(np.abs(Q), 0.1, 1.0)  # or use np.array([0.8] * len(Q))\n",
    "    bl = BlackLittermanModel(\n",
    "        S,\n",
    "        pi=pi,\n",
    "        Q=Q,\n",
    "        P=P,\n",
    "        omega=\"idzorek\",\n",
    "        view_confidences=view_confidences,\n",
    "        tau=0.05\n",
    "    )\n",
    "    logger.debug(\"Sentiment Q vector: \" + str(Q))\n",
    "    logger.debug(\"View confidence: \" + str(view_confidences))\n",
    "\n",
    "    ret_bl = bl.bl_returns()\n",
    "    cov_bl = bl.bl_cov()\n",
    "\n",
    "    logger.debug(\"BL Posterior Returns: \" + str(ret_bl.to_dict()))\n",
    "\n",
    "    # Step 3: Multi-Objective Optimization\n",
    "    class HybridPortfolioProblem(Problem):\n",
    "        def __init__(self):\n",
    "            super().__init__(n_var=len(tickers), n_obj=2, xl=0.0, xu=1.0)\n",
    "            self.ret_bl = ret_bl.values\n",
    "            self.risks = norm_risks\n",
    "\n",
    "        def _evaluate(self, X, out, *args, **kwargs):\n",
    "            ret = np.sum(X * self.ret_bl, axis=1)\n",
    "            risk = np.sum(X * self.risks, axis=1)\n",
    "            out[\"F\"] = np.column_stack([-ret, risk])  # maximize return, minimize risk\n",
    "\n",
    "    problem = HybridPortfolioProblem()\n",
    "    ref_dirs = get_reference_directions(\"das-dennis\", 2, n_partitions=12)\n",
    "    logger.info(\"Running NSGA3 on hybrid portfolio problem\")\n",
    "    res = minimize(\n",
    "        problem=problem,\n",
    "        algorithm=NSGA3(ref_dirs),\n",
    "        termination=(\"n_gen\", 100),\n",
    "        verbose=False\n",
    "    )\n",
    "    logger.debug(\"Optimization complete. Objectives shape: \" + str(res.F.shape))\n",
    "\n",
    "    best_solution = res.X[np.argmin(res.F[:, 1])]\n",
    "    total = np.sum(best_solution)\n",
    "    allocation = {ticker: weight / total for ticker, weight in zip(tickers, best_solution)}\n",
    "\n",
    "    logger.info(\"Final allocation (top 3): \" + str(dict(list(allocation.items())[:3])))\n",
    "    if return_res:\n",
    "        return allocation, dict(ret_bl), res\n",
    "    else:\n",
    "        return allocation, dict(ret_bl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c75f906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Sentiment allocation requested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Running ANN + Sentiment-enhanced predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Running hybrid Blackâ€“Litterman + NSGA3 optimization\n",
      "INFO:__main__:Running NSGA3 on hybrid portfolio problem\n",
      "INFO:__main__:Final allocation (top 3): {'AAPL': 3.610017474220966e-05, 'MSFT': 0.9999638947664377, 'GOOGL': 5.0588200965224175e-09}\n",
      "INFO:__main__:Annualized Return: 19.45%\n",
      "INFO:__main__:Annualized Volatility: 27.09%\n",
      "INFO:__main__:Sharpe Ratio: 0.72\n",
      "INFO:__main__:Sortino Ratio: 1.05\n",
      "INFO:__main__:Max Drawdown: -37.15%\n",
      "INFO:__main__:High weight in MSFT due to lowest predicted variance from ANN simulation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'allocation': {'AAPL': 3.610017474220966e-05,\n",
       "  'MSFT': 0.9999638947664377,\n",
       "  'GOOGL': 5.0588200965224175e-09},\n",
       " 'black_litterman_returns': {'AAPL': 0.2749268088263086,\n",
       "  'MSFT': 0.287397992444769,\n",
       "  'GOOGL': 0.36082800423115025},\n",
       " 'sentiment_scores': {'AAPL': 0.23946203,\n",
       "  'MSFT': 0.36165634,\n",
       "  'GOOGL': 0.5122429},\n",
       " 'metrics': {'Annualized Return': 0.1944585293341084,\n",
       "  'Volatility': 0.27094251863661456,\n",
       "  'Sharpe Ratio': 0.717711381412654,\n",
       "  'Sortino Ratio': 1.05325712269274,\n",
       "  'Max Drawdown': -0.3714771130127735},\n",
       " 'pareto_plot_base64': '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',\n",
       " 'explanation': 'High weight in MSFT due to lowest predicted variance from ANN simulation',\n",
       " 'llm_interpretation': \" Here's a client-friendly interpretation of the portfolio optimization results based on your provided data:\\n\\n1. Asset Allocation: The optimized portfolio should include the following weightings:\\n   - Apple (AAPL): Approximately 0.036%\\n   - Microsoft (MSFT): 99.99%\\n   - Google (GOOGL): 0.059%\\n\\n2. Sentiment Scores: These scores represent the overall sentiments towards the individual stocks, with higher values indicating more positive sentiment. According to the scores:\\n   - Apple (AAPL): Sentiment score of 0.239, suggesting a relatively neutral sentiment\\n   - Microsoft (MSFT): Sentiment score of 0.362, indicating a slightly positive sentiment\\n   - Google (GOOGL): Sentiment score of 0.512, showing a positive sentiment\\n\\n3. Blackâ€“Litterman Expected Returns: These are the estimated future expected returns for each stock, calculated using a combination of market data and your own subjective beliefs:\\n   - Apple (AAPL): Expected return of 0.275%\\n   - Microsoft (MSFT): Expected return of 0.287%\\n   - Google (GOOGL): Expected return of 0.361%\\n\\n4. Predicted Volatility (ANN): These values represent the estimated volatilities (risks) of each stock over the next period, calculated using an Artificial Neural Network (ANN):\\n   - Apple (AAPL): Volatility of 2539.8508, indicating a high-risk stock\\n   - Microsoft (MSFT): Volatility of 1918.323, suggesting a medium-risk stock\\n   - Google (GOOGL): Volatility of 6927.8093, indicating a very high-risk stock\\n\\nIn conclusion, the optimized portfolio consists of primarily Microsoft, with small amounts of Apple and Google. Despite Microsoft having a slightly higher expected return than Apple, it is less volatile, making it a relatively safer investment option. Conversely, Google has a higher expected return but is significantly more volatile, carrying a higher risk. It's essential to consider your risk tolerance and investment goals when making decisions about your portfolio.\"}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Dict, List\n",
    "import tensorflow as tf\n",
    "class SentimentRequest(BaseModel):\n",
    "    tickers: List[str]\n",
    "    duration: str = \"1y\"\n",
    "    \n",
    "def fetch_historical_data(tickers):\n",
    "    data = {}\n",
    "    for ticker in tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        history = stock.history(period=\"5y\")\n",
    "        data[ticker] = history['Close'].values\n",
    "    return data\n",
    "\n",
    "def get_sentiment_scores_for_tickers(tickers):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "    def extract_article_text(url):\n",
    "        try:\n",
    "            article = Article(url)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            return article.text\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def score_text(text):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1).detach().numpy()[0]\n",
    "        return probs[2] - probs[0]\n",
    "\n",
    "    scores = {}\n",
    "    for ticker in tickers:\n",
    "        articles = fetch_articles_from_google_news(ticker) + fetch_yfinance_news(ticker)\n",
    "        articles = extract_text(articles)\n",
    "        texts = [a.get(\"text\") for a in articles if a.get(\"text\")]\n",
    "\n",
    "        if texts:\n",
    "            sentiment_scores = [score_text(t) for t in texts]\n",
    "            scores[ticker] = np.mean(sentiment_scores)  # average polarity\n",
    "        else:\n",
    "            scores[ticker] = 0.0  # neutral\n",
    "\n",
    "    return scores\n",
    "def train_ann(data):\n",
    "    models = {}\n",
    "    for ticker, prices in data.items():\n",
    "        X, y = [], []\n",
    "        for i in range(len(prices) - 10):\n",
    "            X.append(prices[i:i+10])\n",
    "            y.append(prices[i+10])\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        \n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(32, activation='relu', input_shape=(10,)),\n",
    "            tf.keras.layers.Dense(16, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        model.fit(X, y, epochs=50, verbose=0)\n",
    "        models[ticker] = model\n",
    "    return models\n",
    "# def sentiment_optimized_allocation(request):\n",
    "#     logger.info(\"Sentiment allocation requested\")\n",
    "\n",
    "#     tickers = request[\"tickers\"]\n",
    "#     print(tickers)\n",
    "#     data = fetch_historical_data(tickers)\n",
    "#     prices_df = pd.DataFrame({ticker: pd.Series(prices) for ticker, prices in data.items()})\n",
    "#     print(f\"Prices data \\n{prices_df}\")\n",
    "\n",
    "#     sentiment_scores = get_sentiment_scores_for_tickers(tickers)\n",
    "#     logger.debug(f\"sentiment scores: {sentiment_scores}\")\n",
    "#     models = train_ann(data)\n",
    "#     future_prices = predict_with_sentiment_ann(models, data, sentiment_scores, request[\"duration\"])\n",
    "\n",
    "#     allocation, ret_bl = optimize_with_bl_and_moo(future_prices, prices_df, sentiment_scores)\n",
    "\n",
    "#     return {\n",
    "#         \"allocation\": allocation,\n",
    "#         \"black_litterman_returns\": ret_bl,\n",
    "#         \"sentiment_scores\": sentiment_scores\n",
    "#     }\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import base64\n",
    "\n",
    "def plot_pareto_front(res):\n",
    "    F = res.F\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(F[:, 1], -F[:, 0], c='blue', label='Pareto Front')  # x = risk, y = return\n",
    "    plt.xlabel(\"Risk (Objective 2)\")\n",
    "    plt.ylabel(\"Return (Objective 1)\")\n",
    "    plt.title(\"Pareto Front of Portfolio Optimization\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Save plot to base64\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    buf.seek(0)\n",
    "    plot_base64 = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
    "    buf.close()\n",
    "    plt.close()\n",
    "    return plot_base64\n",
    "\n",
    "\n",
    "def compute_portfolio_metrics(historical_prices_df: pd.DataFrame, weights: dict):\n",
    "    returns_df = historical_prices_df.pct_change().dropna()\n",
    "    weight_vector = np.array([weights[ticker] for ticker in returns_df.columns])\n",
    "    portfolio_returns = returns_df @ weight_vector\n",
    "\n",
    "    annualized_return = np.mean(portfolio_returns) * 252\n",
    "    annualized_volatility = np.std(portfolio_returns) * np.sqrt(252)\n",
    "    sharpe_ratio = annualized_return / annualized_volatility if annualized_volatility != 0 else 0\n",
    "\n",
    "    downside_returns = portfolio_returns[portfolio_returns < 0]\n",
    "    sortino_ratio = (np.mean(portfolio_returns) * 252) / (np.std(downside_returns) * np.sqrt(252)) if len(downside_returns) > 0 else 0\n",
    "\n",
    "    cumulative = (1 + portfolio_returns).cumprod()\n",
    "    peak = cumulative.cummax()\n",
    "    drawdown = (cumulative - peak) / peak\n",
    "    max_drawdown = drawdown.min()\n",
    "\n",
    "    logger.info(\"Annualized Return: {:.2%}\".format(annualized_return))\n",
    "    logger.info(\"Annualized Volatility: {:.2%}\".format(annualized_volatility))\n",
    "    logger.info(\"Sharpe Ratio: {:.2f}\".format(sharpe_ratio))\n",
    "    logger.info(\"Sortino Ratio: {:.2f}\".format(sortino_ratio))\n",
    "    logger.info(\"Max Drawdown: {:.2%}\".format(max_drawdown))\n",
    "\n",
    "    return {\n",
    "        \"Annualized Return\": annualized_return,\n",
    "        \"Volatility\": annualized_volatility,\n",
    "        \"Sharpe Ratio\": sharpe_ratio,\n",
    "        \"Sortino Ratio\": sortino_ratio,\n",
    "        \"Max Drawdown\": max_drawdown\n",
    "    }\n",
    "\n",
    "import requests\n",
    "import os\n",
    "def format_interpretation_prompt(allocation, sentiment_scores, bl_returns, future_prices):\n",
    "    volatility = {t: round(np.std(p), 4) for t, p in future_prices.items()}\n",
    "\n",
    "    prompt = (\n",
    "        \"Please interpret this portfolio optimization result:\\n\\n\"\n",
    "        f\"Asset Allocation: {allocation}\\n\"\n",
    "        f\"Sentiment Scores: {sentiment_scores}\\n\"\n",
    "        f\"Blackâ€“Litterman Expected Returns: {bl_returns}\\n\"\n",
    "        f\"Predicted Volatility (ANN): {volatility}\\n\\n\"\n",
    "        \"Provide a client-friendly interpretation in bullet points.\"\n",
    "    )\n",
    "\n",
    "    return prompt\n",
    "def generate_interpretation_openrouter(prompt, model=\"mistralai/mistral-7b-instruct\"):\n",
    "    api_key = \"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\"\n",
    "\n",
    "    # api_key = os.getenv(\"OPENROUTER_API_KEY\")  # store securely or hardcode temporarily\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"HTTP-Referer\": \"http://localhost\",  # or your frontend domain\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    body = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a financial advisor creating easy-to-understand interpretations of portfolio optimization results.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, json=body)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        raise Exception(f\"OpenRouter error: {response.text}\")\n",
    "\n",
    "def sentiment_optimized_allocation(request):\n",
    "    logger.info(\"Sentiment allocation requested\")\n",
    "\n",
    "    tickers = request[\"tickers\"]\n",
    "    duration = request.get(\"duration\", \"1y\")\n",
    "    \n",
    "    data = fetch_historical_data(tickers)\n",
    "    prices_df = pd.DataFrame({ticker: pd.Series(prices) for ticker, prices in data.items()})\n",
    "\n",
    "    sentiment_scores = get_sentiment_scores_for_tickers(tickers)\n",
    "    logger.debug(f\"Sentiment scores: {sentiment_scores}\")\n",
    "\n",
    "    models = train_ann(data)\n",
    "    future_prices = predict_with_sentiment_ann(models, data, sentiment_scores, duration)\n",
    "\n",
    "    # Run optimization and capture res for plotting\n",
    "    allocation, ret_bl, res = optimize_with_bl_and_moo(future_prices, prices_df, sentiment_scores, return_res=True)\n",
    "\n",
    "    # Portfolio metrics\n",
    "    metrics = compute_portfolio_metrics(prices_df, allocation)\n",
    "\n",
    "    # Pareto front\n",
    "    pareto_plot_base64 = plot_pareto_front(res)\n",
    "\n",
    "    # Explainability\n",
    "    sorted_by_risk = sorted(future_prices.items(), key=lambda x: np.std(x[1]))\n",
    "    lowest_risk_ticker = sorted_by_risk[0][0]\n",
    "    logger.info(f\"High weight in {lowest_risk_ticker} due to lowest predicted variance from ANN simulation\")\n",
    "    \n",
    "    prompt = format_interpretation_prompt(allocation, sentiment_scores, ret_bl, future_prices)\n",
    "    interpretation = generate_interpretation_openrouter(prompt)\n",
    "\n",
    "    return {\n",
    "        \"allocation\": allocation,\n",
    "        \"black_litterman_returns\": ret_bl,\n",
    "        \"sentiment_scores\": sentiment_scores,\n",
    "        \"metrics\": metrics,\n",
    "        \"pareto_plot_base64\": pareto_plot_base64,\n",
    "        \"explanation\": f\"High weight in {lowest_risk_ticker} due to lowest predicted variance from ANN simulation\",\n",
    "        \"llm_interpretation\": interpretation\n",
    "    }\n",
    "\n",
    "\n",
    "# req = SentimentRequest({\"tickers\": [\"AAPL\", \"MSFT\", \"GOOGL\"]})\n",
    "sentiment_optimized_allocation({\"tickers\": [\"AAPL\", \"MSFT\", \"GOOGL\"], \"duration\": \"1y\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
